{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81e0caef-7d09-4581-9f97-e27b1f5bee86",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CPSC 483-01: Project 1, Group 5, Fall 2021 \n",
    "**Group Members:**\n",
    "- Nicole Serna\n",
    "- Zachary Serna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "119a5524-572d-4dbd-8019-5250ffb9a86b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Student Name', 'Week 1', 'Week 2', 'Week 3', 'Week 4', 'Week 5']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Experiment 1\n",
    "#importing the csv module\n",
    "import csv\n",
    "#creating a 2D array to hold the data from the csv file\n",
    "data = []\n",
    "with open('participants.csv', newline='') as csvfile:\n",
    "    csvData = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    for row in csvData:\n",
    "        data.append(row)\n",
    "#deleting the header row from \"data\" that was in the csv\n",
    "data.pop(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceeaa8bd-61ca-4da2-844c-91f635e8c77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[77, 179, 180, 180, 183, 178, 174, 181, 180, 173, 178, 183, 180, 174, 177, 178, 179, 179, 177, 177, 51, 170, 175, 175, 176, 175, 175, 175, 170, 174, 175, 174, 9, 170, 24]\n",
      "Mean:  161\n",
      "Median:  175\n"
     ]
    }
   ],
   "source": [
    "#Experiment 2\n",
    "#importing statistics module\n",
    "import statistics as stat\n",
    "#creating a 2D array to only hold week 1 data\n",
    "week1 = []\n",
    "for i in range(len(data)):\n",
    "   week1.append(int(data[i][1]))\n",
    "\n",
    "#finding the mean and median of week 1    \n",
    "print(week1)\n",
    "print('Mean: ', (stat.mean(week1)))\n",
    "print('Median: ', (stat.median(week1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e702747a-a6a9-4e39-b1d6-fefc626d1589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quartiles:  [174.0, 175.0, 179.0]\n"
     ]
    }
   ],
   "source": [
    "#Experiment 3\n",
    "#finding the quartiles of week 1\n",
    "Q = stat.quantiles(week1)\n",
    "print('Quartiles: ', (Q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e9a50e0-65ed-4c24-8eb7-9dfb980ba61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers in Attendence:  ['Adrian Ellison', 'Tayla Sparrow', 'Owain Emerson', 'Alaya Dickinson']\n"
     ]
    }
   ],
   "source": [
    "#Experiment 4\n",
    "#using Tukey's fences to find the outliers in week 1\n",
    "#first we find the upper and lower fences using k = 1.5\n",
    "UpperFence = Q[2]+1.5*(Q[2]-Q[0])\n",
    "LowerFence = Q[0]-1.5*(Q[2]-Q[0])\n",
    "\n",
    "#we create an array to hold the outliers via Tukey's fences.\n",
    "#outliers are values in week1 that fall below the lower fence or above the upperfence.\n",
    "TukeyOutliers = []\n",
    "for a in range(len(week1)):\n",
    "    if (week1[a] < LowerFence) or (week1[a] > UpperFence):\n",
    "        TukeyOutliers.append(data[a][0])\n",
    "print('Outliers in Attendence: ',(TukeyOutliers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6028f17d-0dae-405b-a333-95264b9d5e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers in Attendence V2:  ['Owain Emerson', 'Alaya Dickinson']\n"
     ]
    }
   ],
   "source": [
    "#Experiment 5\n",
    "#using Standard Deviation to find outliers in week 1.\n",
    "#In normal distribution, 99.7% of data falls within 3 Standard Deviations of the mean.\n",
    "#Here, we assume our data is normally distributed.\n",
    "#First we find find the standard deviation of week 1's data.\n",
    "sd = stat.stdev(week1)\n",
    "sdOutliers = []\n",
    "#Then we calculate the values that are 3 SD's away from the mean in the upper and lower directions.\n",
    "upperNormalD = stat.mean(week1) + (3*sd)\n",
    "lowerNormalD = stat.mean(week1) - (3*sd)\n",
    "#Any values that fall above the upper limit or below the lower limit are considered outliers.\n",
    "for a in range(len(week1)):\n",
    "    if (week1[a] < lowerNormalD) or (week1[a] > upperNormalD):\n",
    "        sdOutliers.append(data[a][0])       \n",
    "print('Outliers in Attendence V2: ',(sdOutliers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a564a78-f809-4608-b91f-9f5f82ea815c",
   "metadata": {},
   "source": [
    "### Comparing Outliers: Experiment 4 v. Experiment 5\n",
    "As we can see from the outputs of experiments 4 and 5, the results do not agree with one another. It appears that Adrian Ellison and Tayla Sparrow both fall within 3 standard deviations of the mean. As such they are not considered outliers via the standard deviation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13fc84c5-bcc4-4188-a555-b5f62f10eaa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers in Attendence For Week 2 :  ['Yasir Fenton', 'Tamara Cottrell', 'Jazmin Foreman', 'Bear Zuniga', 'Miles Lyons', 'Owain Emerson']\n"
     ]
    }
   ],
   "source": [
    "#Experiment 6\n",
    "#Defining a function, tardy_iqr, that calculates the outlliers of any weeks data using the Tukey's fences method.\n",
    "def tardy_iqr(weekName):\n",
    "    #first, we determine which week was passed to the function.\n",
    "    if weekName == \"Week 1\":\n",
    "        weekNum = 1\n",
    "    elif weekName == \"Week 2\":\n",
    "        weekNum = 2\n",
    "    elif weekName == \"Week 3\":\n",
    "        weekNum = 3\n",
    "    elif weekName == \"Week 4\":\n",
    "        weekNum = 4\n",
    "    elif weekName == \"Week 5\":\n",
    "        weekNum = 5\n",
    "    else:\n",
    "        print('Not a valid week *frowny face*')\n",
    "        return;\n",
    "    #then we create an array to hold the data of just the week we are interested in.\n",
    "    weekData = []\n",
    "    for i in range(len(data)):\n",
    "       weekData.append(int(data[i][weekNum]))\n",
    "    #now we repeat the steps from problem 4\n",
    "    #We find quartiles, and use those to find the upper and lower fences with k=1.5\n",
    "    #Any data that falls outside of these fences is considered an outlier.\n",
    "    Q = stat.quantiles(weekData)\n",
    "    UFence = Q[2]+1.5*(Q[2]-Q[0])\n",
    "    LFence = Q[0]-1.5*(Q[2]-Q[0])\n",
    "    outliersTukey = []\n",
    "    for a in range(len(weekData)):\n",
    "        if weekData[a] < LFence or weekData[a] > UFence:\n",
    "            outliersTukey.append(data[a][0])\n",
    "    print('Outliers in Attendence For Week',(weekNum), ': ',(outliersTukey))\n",
    "    \n",
    "tardy_iqr(\"Week 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa493c83-195d-4a6d-9542-591a93307527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers in Attendence For Week 3 :  ['Adrian Ellison']\n"
     ]
    }
   ],
   "source": [
    "#Experiment 7\n",
    "#Defining a function, tardy_stdev, that calculates the outliers of any weeks data using the standard deviation method.\n",
    "def tardy_stdev(weekName):\n",
    "    #first, we determine which week was passed to the function\n",
    "    if weekName == \"Week 1\":\n",
    "        weekNum = 1\n",
    "    elif weekName == \"Week 2\":\n",
    "        weekNum = 2\n",
    "    elif weekName == \"Week 3\":\n",
    "        weekNum = 3\n",
    "    elif weekName == \"Week 4\":\n",
    "        weekNum = 4\n",
    "    elif weekName == \"Week 5\":\n",
    "        weekNum = 5\n",
    "    else:\n",
    "        print('Not a valid week *frowny face*')\n",
    "        return;\n",
    "    \n",
    "    weekData = []\n",
    "    #then we create an array to hold just the data from the week we are working with\n",
    "    for i in range(len(data)):\n",
    "       weekData.append(int(data[i][weekNum]))\n",
    "    #we now repeat the steps from problem 5; finding the SD, finding the upper and lower limits, and determining the outliers using these values.\n",
    "    standD = stat.stdev(weekData)\n",
    "    outliersSD = []\n",
    "    UND = stat.mean(weekData) + (3*standD)\n",
    "    LND = stat.mean(weekData) - (3*standD)\n",
    "    for a in range(len(weekData)):\n",
    "        if (weekData[a] < LND) or (week1[a] > UND):\n",
    "            outliersSD.append(data[a][0])       \n",
    "    print('Outliers in Attendence For Week',(weekNum), ': ',(outliersSD))\n",
    "    \n",
    "tardy_stdev(\"Week 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "191c4f85-f501-4b6e-b670-be3afdc5e36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEEK 2:\n",
      "\n",
      "\n",
      "Tukeys Fence:\n",
      "\n",
      "Outliers in Attendence For Week 2 :  ['Yasir Fenton', 'Tamara Cottrell', 'Jazmin Foreman', 'Bear Zuniga', 'Miles Lyons', 'Owain Emerson']\n",
      "\n",
      "\n",
      "\n",
      "Standard Deviation:\n",
      "\n",
      "Outliers in Attendence For Week 2 :  ['Miles Lyons']\n",
      "\n",
      "\n",
      "\n",
      "WEEK 3:\n",
      "\n",
      "\n",
      "Tukeys Fence:\n",
      "\n",
      "Outliers in Attendence For Week 3 :  ['Adrian Ellison', 'Adeline Jordan', 'Jaye Sweeney']\n",
      "\n",
      "\n",
      "\n",
      "Standard Deviation:\n",
      "\n",
      "Outliers in Attendence For Week 3 :  ['Adrian Ellison']\n",
      "\n",
      "\n",
      "\n",
      "WEEK 4:\n",
      "\n",
      "\n",
      "Tukeys Fence:\n",
      "\n",
      "Outliers in Attendence For Week 4 :  ['Dora Delacruz', 'Shaquille Wood']\n",
      "\n",
      "\n",
      "\n",
      "Standard Deviation:\n",
      "\n",
      "Outliers in Attendence For Week 4 :  []\n",
      "\n",
      "\n",
      "\n",
      "WEEK 5:\n",
      "\n",
      "\n",
      "Tukeys Fence:\n",
      "\n",
      "Outliers in Attendence For Week 5 :  ['Jazmin Foreman', 'Sanjay Edwards', 'Alfie-James Pierce', 'Adeline Jordan', 'Saffa Brook']\n",
      "\n",
      "\n",
      "\n",
      "Standard Deviation:\n",
      "\n",
      "Outliers in Attendence For Week 5 :  ['Jazmin Foreman']\n"
     ]
    }
   ],
   "source": [
    "#Experiment 8\n",
    "#WEEK 2\n",
    "print('WEEK 2:\\n\\n')\n",
    "\n",
    "print('Tukeys Fence:\\n')\n",
    "tardy_iqr(\"Week 2\")\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Standard Deviation:\\n')\n",
    "tardy_stdev(\"Week 2\")\n",
    "print('\\n\\n')\n",
    "\n",
    "#WEEK 3\n",
    "print('WEEK 3:\\n\\n')\n",
    "\n",
    "print('Tukeys Fence:\\n')\n",
    "tardy_iqr(\"Week 3\")\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Standard Deviation:\\n')\n",
    "tardy_stdev(\"Week 3\")\n",
    "print('\\n\\n')\n",
    "\n",
    "#WEEK 4\n",
    "print('WEEK 4:\\n\\n')\n",
    "\n",
    "print('Tukeys Fence:\\n')\n",
    "tardy_iqr(\"Week 4\")\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Standard Deviation:\\n')\n",
    "tardy_stdev(\"Week 4\")\n",
    "print('\\n\\n')\n",
    "\n",
    "#WEEK 5\n",
    "print('WEEK 5:\\n\\n')\n",
    "\n",
    "print('Tukeys Fence:\\n')\n",
    "tardy_iqr(\"Week 5\")\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Standard Deviation:\\n')\n",
    "tardy_stdev(\"Week 5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da3eadb-3729-43bd-a291-7f08fc4f818b",
   "metadata": {},
   "source": [
    "### Comparing the results of tardy_iqr() and tardy_stdev() on Weeks 2-5.\n",
    "As we can see from the results above, Tukey's fences seems to be much more lenient in terms of qualifications to be an outlier. As such, if you were trying to find only extreme outliers which may heavily affect your data results, the Standard Deviation approach may be more effective. Tukey's Fences may be appropriate for the scenario provided here; a method to find students missing too many courses."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
