{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71211fd1-4857-47db-9f0b-0516927dba36",
   "metadata": {},
   "source": [
    "# CPSC 483-01: Project 3, Group 5, Fall 2021 \n",
    "**Group Members:**\n",
    "- Nicole Serna\n",
    "- Zachary Serna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a5c3d1d-8691-409b-9331-831e12250b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Experiment 1\n",
    "import pandas as pd\n",
    "#Complete dataSet\n",
    "dataSet = pd.read_csv('bank-additional-full.csv', delimiter=\";\")\n",
    "df = pd.DataFrame(dataSet)\n",
    "df.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0fa2bf-d345-4d65-99ce-041095d2e5d1",
   "metadata": {},
   "source": [
    "Experiment 1 Results/Comments\n",
    "\n",
    "We use pandas to load the csv file in, examining the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aaf9c14-47f8-42e0-b3d2-bc515884089f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Experiment 2\n",
    "\n",
    "#import both sklearn and numpy\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#split the data 90/10 into training and test sets respectively\n",
    "X_train, X_test, y_train, y_test= sklearn.model_selection.train_test_split(dataSet, df.loc[:,\"y\"],test_size=.1,train_size=.9, random_state=(2021-10-25))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea04d15-ebfd-4ef7-bea9-2a3caae9aca1",
   "metadata": {},
   "source": [
    "Experiment 2 Results/Comments\n",
    "\n",
    "We use train_test_split to split the set 90/10 and assign the sets to their appropriate variables in the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b315c9ee-b1a7-4001-b5ae-02ff08917cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Experiment 3\n",
    "\n",
    "#We drop feature y from the set after saving it to variable 'y'\n",
    "y = pd.DataFrame(dataSet, columns=[\"y\"])\n",
    "features = df.drop(columns=[\"duration\", \"y\"])\n",
    "X_train, X_test, y_train, y_test= sklearn.model_selection.train_test_split(features, y,test_size=.1,train_size=.9, random_state=(2021-10-25))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499372f3-e849-42e1-9b7d-64cbecfdfbf9",
   "metadata": {},
   "source": [
    "Experiment 3 Results/Comments\n",
    "\n",
    "After assigning the y feature to its respective variable, we drop it from the rest of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbbdaf15-b40b-4b53-b956-1818153fb120",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Experiment 4\n",
    "\n",
    "\n",
    "bank_client_data_train = pd.DataFrame(X_train, columns=[\"age\",\"job\",\"marital\",\"education\",\"default\",\"housing\",\"loan\"])\n",
    "bank_client_data_test = pd.DataFrame(X_test, columns=[\"age\",\"job\",\"marital\",\"education\",\"default\",\"housing\",\"loan\"])\n",
    "\n",
    "#Properly set the data for future use using get_dummies\n",
    "dummy_bcd_train = pd.get_dummies(bank_client_data_train,drop_first=True)\n",
    "dummy_bcd_test = pd.get_dummies(bank_client_data_test,drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73927a15-42b5-4d33-ba7a-34b534db6b4a",
   "metadata": {},
   "source": [
    "Experiment 4 Results/Comments\n",
    "\n",
    "Since the data we are working with is categorical, we use get dummies to turn our data into quantitative data that we can analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8f21246-b283-4493-802f-de03a3fe073a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikki\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8788540907987376\n",
      "0.8818689470986538\n"
     ]
    }
   ],
   "source": [
    "#Experiment 5\n",
    "\n",
    "#Import Categorical NB, then fit it to the bcd_training set and y_train\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "cnb = CategoricalNB()\n",
    "cnb.fit(dummy_bcd_train,y_train)\n",
    "\n",
    "#Output result\n",
    "print(cnb.score(dummy_bcd_test,y_test))\n",
    "print(cnb.score(dummy_bcd_train,y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264bdb4e-72b0-49d5-bed8-19e0a717be02",
   "metadata": {},
   "source": [
    "Experiment 5 Results/Comments\n",
    "\n",
    "training score:    0.8818689470986538\n",
    "\n",
    "test score:        0.8788540907987376\n",
    "\n",
    "Overall the classifier was fairly accurate. 88% is a fairly high score showing CNB fits the data well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b068d22-bf9c-4e7e-8b41-049abd2a3b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age  job_blue-collar  job_entrepreneur  job_housemaid  job_management  \\\n",
      "22975   56                0                 0              0               0   \n",
      "14746   26                0                 0              0               0   \n",
      "12505   38                0                 0              0               0   \n",
      "6801    33                0                 0              0               0   \n",
      "18389   29                0                 0              0               0   \n",
      "...    ...              ...               ...            ...             ...   \n",
      "17987   31                1                 0              0               0   \n",
      "20299   29                0                 0              0               0   \n",
      "14556   49                1                 0              0               0   \n",
      "28981   47                0                 0              0               0   \n",
      "32764   35                0                 0              0               0   \n",
      "\n",
      "       job_retired  job_self-employed  job_services  job_student  \\\n",
      "22975            1                  0             0            0   \n",
      "14746            0                  0             0            0   \n",
      "12505            0                  0             0            0   \n",
      "6801             0                  0             0            0   \n",
      "18389            0                  0             0            0   \n",
      "...            ...                ...           ...          ...   \n",
      "17987            0                  0             0            0   \n",
      "20299            0                  0             0            0   \n",
      "14556            0                  0             0            0   \n",
      "28981            0                  0             0            0   \n",
      "32764            0                  0             0            0   \n",
      "\n",
      "       job_technician  ...  education_illiterate  \\\n",
      "22975               0  ...                     0   \n",
      "14746               1  ...                     0   \n",
      "12505               0  ...                     0   \n",
      "6801                0  ...                     0   \n",
      "18389               0  ...                     0   \n",
      "...               ...  ...                   ...   \n",
      "17987               0  ...                     0   \n",
      "20299               1  ...                     0   \n",
      "14556               0  ...                     0   \n",
      "28981               0  ...                     0   \n",
      "32764               0  ...                     0   \n",
      "\n",
      "       education_professional.course  education_university.degree  \\\n",
      "22975                              1                            0   \n",
      "14746                              1                            0   \n",
      "12505                              0                            0   \n",
      "6801                               0                            1   \n",
      "18389                              0                            0   \n",
      "...                              ...                          ...   \n",
      "17987                              1                            0   \n",
      "20299                              0                            0   \n",
      "14556                              0                            0   \n",
      "28981                              0                            0   \n",
      "32764                              0                            1   \n",
      "\n",
      "       education_unknown  default_unknown  default_yes  housing_unknown  \\\n",
      "22975                  0                0            0                0   \n",
      "14746                  0                0            0                1   \n",
      "12505                  0                0            0                0   \n",
      "6801                   0                0            0                0   \n",
      "18389                  0                0            0                0   \n",
      "...                  ...              ...          ...              ...   \n",
      "17987                  0                0            0                0   \n",
      "20299                  0                0            0                0   \n",
      "14556                  0                1            0                0   \n",
      "28981                  0                0            0                0   \n",
      "32764                  0                0            0                0   \n",
      "\n",
      "       housing_yes  loan_unknown  loan_yes  \n",
      "22975            1             0         0  \n",
      "14746            0             1         0  \n",
      "12505            1             0         0  \n",
      "6801             0             0         0  \n",
      "18389            0             0         0  \n",
      "...            ...           ...       ...  \n",
      "17987            1             0         0  \n",
      "20299            0             0         0  \n",
      "14556            1             0         0  \n",
      "28981            1             0         0  \n",
      "32764            1             0         0  \n",
      "\n",
      "[37069 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "#Taking a look at the data used in the previous experiment (expirement 5)\n",
    "print(dummy_bcd_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a62b0c1-2fdb-4f6d-b9f1-749860031613",
   "metadata": {},
   "source": [
    "Experiment 6 Response\n",
    "\n",
    "Even though Categorical Naive Bayes assumes that each value of the age variable is a separate category, in our data used in the previous expeirment, there is only one category for the age variable. This is not reasonable when using the Categorical Naive Bayes classifier, since it is assuming that each age is a serparete column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df109051-6890-478f-a987-1f8b795849a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikki\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8788540907987376\n",
      "0.881437319593191\n"
     ]
    }
   ],
   "source": [
    "#Experiment 7\n",
    "\n",
    "\n",
    "#Set up for division\n",
    "bins = [0,10,20,30,40,50,60,70,80,90,100]\n",
    "labels = ['0-10','11-20','21-30','31-40','41-50','51-60','61-70','71-80','81-90','91-100']\n",
    "bcd_train_ageSplit = bank_client_data_train\n",
    "\n",
    "#splits age into appropriate bins and then use get_dummies to set the data up\n",
    "#for later use\n",
    "bcd_train_ageSplit['Age_Category'] = pd.cut(bank_client_data_train['age'], bins= bins, labels= labels)\n",
    "bcd_train_ageSplit = bcd_train_ageSplit.drop(columns=['age'])\n",
    "dummy_bcd_train_ageSplit = pd.get_dummies(bcd_train_ageSplit,drop_first=True)\n",
    "\n",
    "bcd_test_ageSplit = bank_client_data_test\n",
    "bcd_test_ageSplit['Age_Category'] = pd.cut(bank_client_data_test['age'], bins= bins, labels= labels)\n",
    "bcd_test_ageSplit = bcd_test_ageSplit.drop(columns=['age'])\n",
    "dummy_bcd_test_ageSplit = pd.get_dummies(bcd_test_ageSplit,drop_first=True)\n",
    "\n",
    "#fits data to see how well it fits the CNB classifier\n",
    "cnb.fit(dummy_bcd_train_ageSplit,y_train)\n",
    "print(cnb.score(dummy_bcd_test_ageSplit,y_test))\n",
    "print(cnb.score(dummy_bcd_train_ageSplit,y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5a0011-5c89-4d67-b4e0-8521d21be752",
   "metadata": {},
   "source": [
    "Experiment 7 Results/Comments\n",
    "\n",
    "training score: 0.881437319593191\n",
    "\n",
    "test score:     0.8788540907987376\n",
    "\n",
    "Based on the results above, we can see setting the data into bins had little to no effect on the data, only VERY slightly decreasing the accuracy of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffbe1c34-35b6-40c8-a568-142c382485e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikki\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8771546491866958\n",
      "0.8903935903315439\n"
     ]
    }
   ],
   "source": [
    "#Experiment 8\n",
    "\n",
    "\n",
    "#KNN classifier, we chose to use the default number of neighbors: 5\n",
    "from sklearn import neighbors\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(dummy_bcd_train,y_train)\n",
    "print(knn.score(dummy_bcd_test,y_test))\n",
    "print(knn.score(dummy_bcd_train,y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926ade86-3913-4a62-b183-dfd629f477f1",
   "metadata": {},
   "source": [
    "Experiment 8 Results/Comments\n",
    "\n",
    "KNN training score:    0.8903935903315439\n",
    "\n",
    "KNN test score:        0.8771546491866958\n",
    "\n",
    "\n",
    "Based on the results above, we can see that both the test and training scores are extremely similar to those of the CategoricalNB classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07db0615-673c-4e34-9177-33e1afcd3b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     3646\n",
       "yes     473\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Experiment 9\n",
    "\n",
    "#returns counts of no(0) and yes(1)\n",
    "y_test['y'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2384b79a-2ccf-4b07-a5ac-c50bb41105ce",
   "metadata": {},
   "source": [
    "Experiment 9 Results/Comments\n",
    "\n",
    "no     3646\n",
    "\n",
    "yes     473p\n",
    "\n",
    "Name: y, dtype: int64\n",
    "\n",
    "We can see from the results above that 3646 have response 0 (no), while 473 have response 1 (yes). If we simply assumed that no customer ever subscribed to the product, then the score would be 3646/4119, which would be roughly 88%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a957b2b9-8680-4ca2-8a79-f998eabd88d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[3646    0]\n",
      " [ 473    0]]\n",
      "AUC Score:\n",
      " 0.5\n"
     ]
    }
   ],
   "source": [
    "#Experiment 10\n",
    "\n",
    "#we import the confusion matrix and roc funcs from sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#create a dummy set of only 0's and score it against our y_test\n",
    "dumb_class = np.zeros_like(y_test, dtype='uint')\n",
    "y_test_dummy = pd.get_dummies(y_test, drop_first =True)\n",
    "conf_matrix = confusion_matrix(y_test_dummy.values,dumb_class)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "#Calculating AUC score \n",
    "score_auc = roc_auc_score(y_test_dummy.values,dumb_class)\n",
    "print(\"AUC Score:\\n\", score_auc )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f5e85f-b3a4-41e4-9356-dfbf8dc9b1ef",
   "metadata": {},
   "source": [
    "Experiment 10 Results/Comments\n",
    "\n",
    "Confusion Matrix:\n",
    "\n",
    " [[3646    0]\n",
    " \n",
    " [ 473    0]]\n",
    " \n",
    "AUC Score:\n",
    " 0.5\n",
    "\n",
    "\n",
    "We end up with a AUC score of .5 which is much lower than our previous results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee7f7a39-b8af-4929-9b54-238ee6714aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8788540907987376\n",
      "Confusion Matrix:\n",
      " [[3554  407]\n",
      " [  92   66]]\n",
      "CategoricalNB - ROC AUC score 0.6389724207594062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikki\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:949: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\"No positive samples in y_true, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix KNN:\n",
      " [[3559  419]\n",
      " [  87   54]]\n",
      "KNN - ROC AUC score 0.6142052050438431\n"
     ]
    }
   ],
   "source": [
    "#Experiment 11\n",
    "\n",
    "#We use the predict and score functions on our ageSplit set\n",
    "#we then use the result of predict for our confusion matrix\n",
    "pred_bins = cnb.predict(dummy_bcd_test_ageSplit)\n",
    "score_bins = cnb.score(dummy_bcd_test_ageSplit,y_test)\n",
    "print(\"Score:\", score_bins)\n",
    "conf_matrix_bins = confusion_matrix(pred_bins, y_test)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix_bins)\n",
    "\n",
    "\n",
    "#Calculating AUC for ageSplit set\n",
    "predictProb_y = cnb.predict_proba(dummy_bcd_test_ageSplit)[:,1]\n",
    "fps, tps, thresholds = roc_curve(y_test, predictProb_y,pos_label=1)\n",
    "roc_score = roc_auc_score(y_test, predictProb_y)\n",
    "print(\"CategoricalNB - ROC AUC score\", roc_score)\n",
    "\n",
    "#Confusion Matrix for KNN set\n",
    "pred_KNN = knn.predict(dummy_bcd_test)\n",
    "conf_matrix_KNN = confusion_matrix(pred_KNN, y_test)\n",
    "print(\"Confusion Matrix KNN:\\n\", conf_matrix_KNN)\n",
    "\n",
    "#Calculating AUC for KNN\n",
    "predictProb_KNN = knn.predict_proba(dummy_bcd_test)[:,1]\n",
    "roc_score_KNN = roc_auc_score(y_test, predictProb_KNN)\n",
    "print(\"KNN - ROC AUC score\", roc_score_KNN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43327820-59b2-4950-ae79-4463c6c5ca0f",
   "metadata": {},
   "source": [
    "Experiment 11 Results/Comments\n",
    "\n",
    "Confusion Matrix:\n",
    "\n",
    " [[3554  407]\n",
    " \n",
    " [  92   66]]\n",
    "\n",
    "\n",
    "CategoricalNB - ROC AUC score 0.6389724207594062\n",
    "\n",
    "Confusion Matrix KNN:\n",
    "\n",
    " [[3554  407]\n",
    " \n",
    " [  92   66]]\n",
    " \n",
    "KNN - ROC AUC score 0.6142052050438431\n",
    "\n",
    "\n",
    "\n",
    "The classifiers are performing much more poorly than shown in our previous experiments, showing a potential imbalance in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "070e1256-0976-4ae4-9a6a-e548319b0717",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Experiment 12\n",
    "\n",
    "y_0_count = (dataSet.y == 'no').sum()\n",
    "y_no_df = dataSet.drop(dataSet[dataSet.y == 'yes'].index)\n",
    "dataSetWeight = dataSet\n",
    "dataSetWeight['weight'] = 1\n",
    "dataSetWeight['weight'] = dataSetWeight['weight'].where(dataSet.y == 'yes', '0')\n",
    "y_overSample = dataSetWeight.sample(n = y_0_count, weights = 'weight', replace = True, random_state=(2021-10-25))\n",
    "df_overSample = pd.concat([y_no_df, y_overSample], axis=0)\n",
    "\n",
    "#Recreating test/training set, seperating target variable\n",
    "y_OS = pd.DataFrame(df_overSample, columns=[\"y\"])\n",
    "features_OS = df_overSample.drop(columns=[\"duration\", \"y\", \"weight\"])\n",
    "X_train_OS, X_test_OS, y_train_OS, y_test_OS= sklearn.model_selection.train_test_split(features_OS, y_OS,test_size=.1,train_size=.9, random_state=(2021-10-25))\n",
    "\n",
    "#dropping the non-bank client data columns\n",
    "#running get dummies again for categorical variables\n",
    "bcd_OS_train = pd.DataFrame(X_train_OS, columns=[\"age\",\"job\",\"marital\",\"education\",\"default\",\"housing\",\"loan\"])\n",
    "bcd_OS_test = pd.DataFrame(X_test_OS, columns=[\"age\",\"job\",\"marital\",\"education\",\"default\",\"housing\",\"loan\"])\n",
    "dummy_bcdOS_train = pd.get_dummies(bcd_OS_train,drop_first=True)\n",
    "dummy_bcdOS_test = pd.get_dummies(bcd_OS_test,drop_first=True)\n",
    "#because of the way our train/test sets are split, the test set ends up with no values for this column, so it deletes it\n",
    "#but in order to run CNB we need the train and test set to have the same number of columns\n",
    "#so we add the 'default_yes' column to the test set but fill it with all zeros\n",
    "dummy_bcdOS_test['default_yes'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a4e921-c717-4797-b0ba-b32679245087",
   "metadata": {},
   "source": [
    "Experiment 12 Results/Comments\n",
    "\n",
    "\n",
    "We create a new dataset which places more weight on response 1, which would be 'yes' in this scenario. To do this we oversample users with response yes, in order to have an even split of individuals with response yes and individuals with response no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7132e0ba-bea0-46c0-9c53-cf880e1e1221",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikki\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6049247606019151\n",
      "0.609354573921503\n",
      "Confusion Matrix CategoricalNB:\n",
      " [[2325 1560]\n",
      " [1328 2097]]\n",
      "CategoricalNB - ROC AUC score 0.6541865230992601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikki\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix KNN:\n",
      " [[2361 1337]\n",
      " [1292 2320]]\n",
      "KNN - ROC AUC score 0.6917650252963896\n"
     ]
    }
   ],
   "source": [
    "#Experiment 13\n",
    "\n",
    "#retraining categorical naive bayes\n",
    "cnb = CategoricalNB()\n",
    "cnb.fit(dummy_bcdOS_train,y_train_OS)\n",
    "print(cnb.score(dummy_bcdOS_test,y_test_OS))\n",
    "print(cnb.score(dummy_bcdOS_train,y_train_OS))\n",
    "\n",
    "pred_OS_cnb = cnb.predict(dummy_bcdOS_test)\n",
    "conf_matrix_cnb_OS = confusion_matrix(pred_OS_cnb, y_test_OS)\n",
    "print(\"Confusion Matrix CategoricalNB:\\n\", conf_matrix_cnb_OS)\n",
    "\n",
    "predictProb_y_OS_cnb = cnb.predict_proba(dummy_bcdOS_test)[:,1]\n",
    "roc_score_cnbOS = roc_auc_score(y_test_OS, predictProb_y_OS_cnb)\n",
    "print(\"CategoricalNB - ROC AUC score\", roc_score_cnbOS)\n",
    "\n",
    "#retrain KNN with balanced data\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(dummy_bcdOS_train,y_train_OS)\n",
    "##print(knn.score(dummy_bcdOS_test,y_test_OS))\n",
    "##print(knn.score(dummy_bcdOS_train,y_train_OS))\n",
    "pred_KNN_OS = knn.predict(dummy_bcdOS_test)\n",
    "conf_matrix_KNN_OS = confusion_matrix(pred_KNN_OS, y_test_OS)\n",
    "print(\"Confusion Matrix KNN:\\n\", conf_matrix_KNN_OS)\n",
    "\n",
    "predictProb_KNN_OS = knn.predict_proba(dummy_bcdOS_test)[:,1]\n",
    "roc_score_KNN_OS = roc_auc_score(y_test_OS, predictProb_KNN_OS)\n",
    "print(\"KNN - ROC AUC score\", roc_score_KNN_OS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4c2e40-a399-4037-a361-2f9cea52b53a",
   "metadata": {},
   "source": [
    "Experiment 13 Results/Comments\n",
    "\n",
    "Confusion Matrix CategoricalNB:\n",
    " [[2325 1560]\n",
    " \n",
    " [1328 2097]]\n",
    " \n",
    "CategoricalNB - ROC AUC score 0.6541865230992601\n",
    "\n",
    "Confusion Matrix KNN:\n",
    " [[2361 1337]\n",
    " \n",
    " [1292 2320]]\n",
    "KNN - ROC AUC score 0.6917650252963896\n",
    "\n",
    "\n",
    "As we can see from the results above, The KNN classifier performs slightly better than the CNB classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39a5b9ac-d48b-471c-87ca-cfe28d36d8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8720563243505706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikki\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8761768593703634\n",
      "Confusion Matrix CategoricalNB:\n",
      " [[3490  371]\n",
      " [ 156  102]]\n",
      "CategoricalNB - ROC AUC score 0.7016899402629543\n"
     ]
    }
   ],
   "source": [
    "#Experiment 14\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "\n",
    "bc_data_train = pd.DataFrame(X_train, columns=[ \"emp.var.rate\", \"cons.price.idx\", \"cons.price.idx\", \"cons.conf.idx\", \"euribor3m\" \"nr.employed\"])\n",
    "bc_data_test = pd.DataFrame(X_test, columns=[ \"emp.var.rate\", \"cons.price.idx\", \"cons.price.idx\", \"cons.conf.idx\", \"euribor3m\" \"nr.employed\"])\n",
    "\n",
    "bc_data_train = bc_data_train.fillna(0)\n",
    "bc_data_test = bc_data_test.fillna(0)\n",
    "\n",
    "\n",
    "#Properly set the data for future use using get_dummies\n",
    "#dum_bcd_train = pd.get_dummies(bc_data_train,drop_first=True)\n",
    "#dum_bcd_test = pd.get_dummies(bc_data_test,drop_first=True)\n",
    "\n",
    "\n",
    "\n",
    "#dum_bcd_train.fillnaN(0)\n",
    "#Import Categorical NB, then fit it to the bcd_training set and y_train\n",
    "gnb.fit(bc_data_train,y_train)\n",
    "\n",
    "gnb.predict(bc_data_test)\n",
    "\n",
    "#Output result\n",
    "print(gnb.score(bc_data_test,y_test))\n",
    "print(gnb.score(bc_data_train,y_train))\n",
    "\n",
    "#Confusion Matrix\n",
    "pred_gnb = gnb.predict(bc_data_test)\n",
    "conf_matrix_gnb = confusion_matrix(pred_gnb, y_test)\n",
    "print(\"Confusion Matrix CategoricalNB:\\n\", conf_matrix_gnb)\n",
    "\n",
    "#AUC score\n",
    "predictProb_gnb = gnb.predict_proba(bc_data_test)[:,1]\n",
    "roc_score_gnb = roc_auc_score(y_test, predictProb_gnb)\n",
    "print(\"CategoricalNB - ROC AUC score\", roc_score_gnb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01993e7-dd49-4ac1-b82d-89b32c3a6388",
   "metadata": {},
   "source": [
    "Experiment 14 Results/Comments\n",
    "\n",
    "training score:     0.8761768593703634\n",
    "\n",
    "test score:         0.8720563243505706\n",
    "\n",
    "Confusion Matrix CategoricalNB:\n",
    " [[3490  371]\n",
    " [ 156  102]]\n",
    "CategoricalNB - ROC AUC score 0.7016899402629543\n",
    "\n",
    "Overall, the data does a subpar job of predicting the data. While it is an improvement over previous AUC scores we have observed, 70% is still a relatively low number in terms of reliability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35811deb-3031-4b03-9f41-f5e862c6dbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikki\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6574555403556771\n",
      "0.6518104155899431\n",
      "Confusion Matrix CategoricalNB:\n",
      " [[2710 1561]\n",
      " [ 943 2096]]\n",
      "CategoricalNB - ROC AUC score 0.7111010230465242\n"
     ]
    }
   ],
   "source": [
    "#Experiment 15\n",
    "\n",
    "\n",
    "#Pull columns/features we are interested in analyzing\n",
    "sac_data_train = pd.DataFrame(X_train_OS, columns=[ \"emp.var.rate\", \"cons.price.idx\", \"cons.price.idx\", \"cons.conf.idx\", \"euribor3m\" \"nr.employed\"])\n",
    "sac_data_test = pd.DataFrame(X_test_OS, columns=[ \"emp.var.rate\", \"cons.price.idx\", \"cons.price.idx\", \"cons.conf.idx\", \"euribor3m\" \"nr.employed\"])\n",
    "\n",
    "sac_data_train = sac_data_train.fillna(0)\n",
    "sac_data_test = sac_data_test.fillna(0)\n",
    "\n",
    "#Import Categorical NB, then fit it to the bcd_training set and y_train\n",
    "gnb.fit(sac_data_train,y_train_OS)\n",
    "\n",
    "gnb.predict(sac_data_test)\n",
    "\n",
    "#Output result\n",
    "print(gnb.score(sac_data_test,y_test_OS))\n",
    "print(gnb.score(sac_data_train,y_train_OS))\n",
    "\n",
    "#Confusion Matrix\n",
    "#print\n",
    "pred_gnb_balance = gnb.predict(sac_data_test)\n",
    "conf_matrix_gnb_balance = confusion_matrix(pred_gnb_balance, y_test_OS)\n",
    "print(\"Confusion Matrix CategoricalNB:\\n\", conf_matrix_gnb_balance)\n",
    "\n",
    "predictProb_gnb_balance = gnb.predict_proba(sac_data_test)[:,1]\n",
    "roc_score_gnb_balance = roc_auc_score(y_test_OS, predictProb_gnb_balance)\n",
    "print(\"CategoricalNB - ROC AUC score\", roc_score_gnb_balance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72705619-b924-4699-ac68-f7f491f90077",
   "metadata": {},
   "source": [
    "Experiment 15 Results/Comments\n",
    "\n",
    "Training Score: 0.6518104155899431\n",
    "\n",
    "Test Score:     0.6574555403556771\n",
    "\n",
    "Confusion Matrix CategoricalNB:\n",
    "\n",
    " [[2710 1561]\n",
    " \n",
    " [ 943 2096]]\n",
    " \n",
    "CategoricalNB - ROC AUC score 0.7111010230465242\n",
    "\n",
    "\n",
    "The results do change. Both the training and test score decrease; however, the AUC score increases very slightly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
